-- Refresh source timestamps and add additional latest open/closed models for LLM Galaxy.

insert into public.llm_source_updates (source_name, source_url, source_updated_on, notes, synced_at)
values
  ('Vellum LLM Leaderboard', 'https://www.vellum.ai/llm-leaderboard', '2025-12-15', 'Main leaderboard snapshot.', now()),
  ('Vellum Open LLM Leaderboard', 'https://www.vellum.ai/open-llm-leaderboard', '2025-11-19', 'Open leaderboard snapshot.', now()),
  ('Hugging Face Open LLM Leaderboard', 'https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard#/', '2026-01-26', 'Rolling updates; latest release observed on Jan 26, 2026.', now())
on conflict (source_name) do update set
  source_url = excluded.source_url,
  source_updated_on = excluded.source_updated_on,
  notes = excluded.notes,
  synced_at = excluded.synced_at,
  updated_at = now();

insert into public.llm_models (
  slug,
  name,
  company,
  description,
  logo,
  color,
  parameters,
  context_window,
  pricing,
  speed,
  architecture,
  is_open_source,
  is_multimodal,
  benchmarks,
  strengths,
  weaknesses,
  use_cases,
  considerations,
  api_docs_url,
  homepage_url,
  huggingface_url,
  license,
  versions,
  is_trending,
  release_date
)
values
(
  'gpt-5-1',
  'GPT 5.1',
  'OpenAI',
  'Frontier proprietary model variant used for advanced reasoning and coding workflows.',
  'https://logo.clearbit.com/openai.com',
  'from-emerald-500 to-cyan-600',
  null,
  '400k',
  '$$',
  'Fast',
  'Transformer',
  false,
  true,
  jsonb_build_object(
    'gpqa', 94.2,
    'aime_2025', 91.6,
    'swe_bench', 82.1,
    'bfcl', 87.8,
    'grind', 60.1,
    'livecode', 84.9,
    'aider_polyglot', 90.8,
    'speed_tokens_per_sec', 96,
    'latency_ttft_sec', 0.55,
    'input_cost_per_1m', 2.0,
    'output_cost_per_1m', 16,
    'coding_score', 95,
    'reasoning_score', 96,
    'voice_score', 90,
    'stt_score', 91,
    'tts_score', 90,
    's2s_score', 88,
    'image_gen_score', 83,
    'video_gen_score', 77,
    'general_score', 95
  ),
  array['Top-tier reasoning and coding', 'Strong multi-step tool use', 'High enterprise quality bar'],
  array['Premium pricing for large scale usage'],
  array['Reasoning', 'Coding', 'Agents', 'Chatbots', 'RAG', 'Multimodal'],
  array['Validate unit economics against traffic forecast'],
  'https://platform.openai.com/docs',
  'https://openai.com',
  null,
  'Proprietary',
  '[{"name":"GPT 5.1","highlight":"Frontier closed-source quality"}]'::jsonb,
  true,
  'Jan 2026'
),
(
  'claude-sonnet-4-5',
  'Claude Sonnet 4.5',
  'Anthropic',
  'Balanced high-performance model for coding assistants and long-context enterprise workflows.',
  'https://logo.clearbit.com/anthropic.com',
  'from-orange-500 to-amber-600',
  null,
  '200k',
  '$$',
  'Fast',
  'Transformer',
  false,
  true,
  jsonb_build_object(
    'gpqa', 90.1,
    'aime_2025', 88.3,
    'swe_bench', 79.7,
    'bfcl', 84.6,
    'grind', 56.2,
    'livecode', 80.4,
    'aider_polyglot', 88.8,
    'speed_tokens_per_sec', 78,
    'latency_ttft_sec', 0.85,
    'input_cost_per_1m', 3,
    'output_cost_per_1m', 15,
    'coding_score', 93,
    'reasoning_score', 92,
    'general_score', 92
  ),
  array['Great coding quality', 'Excellent long context consistency'],
  array['Cost can rise in high-volume deployments'],
  array['Coding', 'Reasoning', 'Chatbots', 'Agents', 'RAG', 'Enterprise'],
  array['Benchmark against your domain prompts before rollout'],
  'https://docs.anthropic.com',
  'https://www.anthropic.com',
  null,
  'Proprietary',
  '[{"name":"Claude Sonnet 4.5","highlight":"Balanced quality and speed"}]'::jsonb,
  true,
  'Jan 2026'
),
(
  'gemini-2-5-pro',
  'Gemini 2.5 Pro',
  'Google',
  'Google proprietary flagship variant optimized for multimodal reasoning and coding tasks.',
  'https://logo.clearbit.com/google.com',
  'from-blue-500 to-indigo-600',
  null,
  '2M+',
  '$$',
  'Fast',
  'Multimodal Transformer',
  false,
  true,
  jsonb_build_object(
    'gpqa', 91.5,
    'aime_2025', 90.4,
    'swe_bench', 76.8,
    'bfcl', 82.5,
    'grind', 58.1,
    'livecode', 79.6,
    'aider_polyglot', 83.4,
    'speed_tokens_per_sec', 126,
    'latency_ttft_sec', 0.68,
    'input_cost_per_1m', 2,
    'output_cost_per_1m', 12,
    'coding_score', 92,
    'reasoning_score', 94,
    'voice_score', 89,
    'stt_score', 88,
    'tts_score', 87,
    's2s_score', 85,
    'image_gen_score', 87,
    'video_gen_score', 82,
    'general_score', 93
  ),
  array['Strong multimodal intelligence', 'Excellent reasoning and math profile'],
  array['API features can vary by region and tier'],
  array['Reasoning', 'Coding', 'Multimodal', 'Agents', 'Voice', 'Image Generation', 'Video Generation'],
  array['Check regional model availability for production'],
  'https://ai.google.dev/gemini-api/docs',
  'https://deepmind.google/technologies/gemini/',
  null,
  'Proprietary',
  '[{"name":"Gemini 2.5 Pro","highlight":"Top-tier multimodal reasoning"}]'::jsonb,
  true,
  '2026'
),
(
  'qwen3-235b-thinking',
  'Qwen3 235B Thinking',
  'Qwen',
  'Large open-weight reasoning-focused model family variant popular in open leaderboard evaluations.',
  'https://logo.clearbit.com/huggingface.co',
  'from-indigo-500 to-blue-600',
  '235B',
  '131072',
  '$',
  'Medium',
  'Transformer',
  true,
  true,
  jsonb_build_object(
    'gpqa', 83.8,
    'aime_2025', 87.5,
    'swe_bench', 67.8,
    'bfcl', 72.2,
    'grind', 53.2,
    'livecode', 75.6,
    'aider_polyglot', 79.3,
    'speed_tokens_per_sec', 88,
    'latency_ttft_sec', 0.95,
    'input_cost_per_1m', 0.6,
    'output_cost_per_1m', 2.1,
    'coding_score', 90,
    'reasoning_score', 90,
    'general_score', 88
  ),
  array['Very strong open reasoning profile', 'Competitive coding capability'],
  array['Requires careful infra planning for self-hosted deployments'],
  array['Open source', 'Reasoning', 'Coding', 'Agents', 'RAG'],
  array['Use quantized variants for cost-sensitive inference'],
  'https://qwen.readthedocs.io',
  'https://qwenlm.github.io',
  'https://huggingface.co/Qwen',
  'Open model license terms vary by release',
  '[{"name":"Qwen3 235B Thinking","highlight":"Open reasoning-focused variant"}]'::jsonb,
  true,
  '2026'
),
(
  'llama-4-maverick',
  'Llama 4 Maverick',
  'Meta',
  'Open-weight high-throughput model for broad assistant and coding use cases.',
  'https://logo.clearbit.com/meta.com',
  'from-violet-500 to-fuchsia-600',
  null,
  '131072',
  '$',
  'Very Fast',
  'Transformer',
  true,
  true,
  jsonb_build_object(
    'gpqa', 76.2,
    'aime_2025', 78.9,
    'swe_bench', 46.4,
    'bfcl', 66.9,
    'grind', 48.6,
    'livecode', 64.5,
    'aider_polyglot', 67.2,
    'speed_tokens_per_sec', 1800,
    'latency_ttft_sec', 0.36,
    'input_cost_per_1m', 0.14,
    'output_cost_per_1m', 0.52,
    'coding_score', 84,
    'reasoning_score', 82,
    'general_score', 82
  ),
  array['High throughput and low latency', 'Strong open ecosystem support'],
  array['Frontier quality below top closed-source models'],
  array['Open source', 'Chatbots', 'Coding', 'Agents', 'RAG'],
  array['Great for cost and speed optimized workloads'],
  'https://ai.meta.com/llama/',
  'https://ai.meta.com/llama/',
  'https://huggingface.co/meta-llama',
  'Meta Llama license terms vary by release',
  '[{"name":"Llama 4 Maverick","highlight":"High-throughput open model"}]'::jsonb,
  true,
  '2026'
),
(
  'deepseek-v3-1',
  'DeepSeek V3.1',
  'DeepSeek',
  'Open reasoning and coding model with strong value/performance profile.',
  'https://logo.clearbit.com/deepseek.com',
  'from-fuchsia-500 to-rose-600',
  null,
  '131072',
  '$',
  'Fast',
  'Transformer',
  true,
  false,
  jsonb_build_object(
    'gpqa', 79.6,
    'aime_2025', 84.2,
    'swe_bench', 58.6,
    'bfcl', 69.7,
    'grind', 52.4,
    'livecode', 73.2,
    'aider_polyglot', 74.1,
    'speed_tokens_per_sec', 150,
    'latency_ttft_sec', 0.62,
    'input_cost_per_1m', 0.22,
    'output_cost_per_1m', 0.95,
    'coding_score', 89,
    'reasoning_score', 88,
    'general_score', 86
  ),
  array['Strong open coding and reasoning mix', 'Good cost-performance efficiency'],
  array['May need stricter safety guardrails for automation'],
  array['Open source', 'Coding', 'Reasoning', 'Agents', 'RAG'],
  array['Apply policy checks for high-risk workflows'],
  'https://huggingface.co/deepseek-ai',
  'https://www.deepseek.com',
  'https://huggingface.co/deepseek-ai',
  'DeepSeek license (varies)',
  '[{"name":"DeepSeek V3.1","highlight":"Strong open-value profile"}]'::jsonb,
  true,
  '2026'
)
on conflict (slug) do update set
  name = excluded.name,
  company = excluded.company,
  description = excluded.description,
  logo = excluded.logo,
  color = excluded.color,
  parameters = excluded.parameters,
  context_window = excluded.context_window,
  pricing = excluded.pricing,
  speed = excluded.speed,
  architecture = excluded.architecture,
  is_open_source = excluded.is_open_source,
  is_multimodal = excluded.is_multimodal,
  benchmarks = excluded.benchmarks,
  strengths = excluded.strengths,
  weaknesses = excluded.weaknesses,
  use_cases = excluded.use_cases,
  considerations = excluded.considerations,
  api_docs_url = excluded.api_docs_url,
  homepage_url = excluded.homepage_url,
  huggingface_url = excluded.huggingface_url,
  license = excluded.license,
  versions = excluded.versions,
  is_trending = excluded.is_trending,
  release_date = excluded.release_date,
  updated_at = now();
